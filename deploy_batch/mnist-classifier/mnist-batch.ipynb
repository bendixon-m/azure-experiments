{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and manage a batch endpoint for inferencing\n",
    "\n",
    "**Motivations** - In this example, we're going to deploy a model to solve the classic MNIST (\"Modified National Institute of Standards and Technology\") digit recognition problem to perform batch inferencing over large amounts of data (image files). In the first section of this tutorial, we're going to create a batch deployment with a model created using Torch. Such deployment will become our default one in the endpoint. In the second half, we're going to see how we can create a second deployment using a model created with TensorFlow (Keras), test it out, and then switch the endpoint to start using the new deployment as default once we confirm it is working.. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect to Azure Machine Learning Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mA web browser has been opened at https://login.microsoftonline.com/organizations/oauth2/v2.0/authorize. Please continue the login in the web browser. If no web browser is available or if the web browser fails to open, use device code flow with `az login --use-device-code`.\u001b[0m\n",
      "[\n",
      "  {\n",
      "    \"cloudName\": \"AzureCloud\",\n",
      "    \"homeTenantId\": \"7b658efc-8cee-4580-b989-85db158d4e3c\",\n",
      "    \"id\": \"3979595d-b401-4ff4-b3ef-661b8481c742\",\n",
      "    \"isDefault\": true,\n",
      "    \"managedByTenants\": [\n",
      "      {\n",
      "        \"tenantId\": \"961897a7-5808-4b80-b503-dbb7be13e7a7\"\n",
      "      }\n",
      "    ],\n",
      "    \"name\": \"MV-AZU-001\",\n",
      "    \"state\": \"Enabled\",\n",
      "    \"tenantId\": \"7b658efc-8cee-4580-b989-85db158d4e3c\",\n",
      "    \"user\": {\n",
      "      \"name\": \"ben.dixon@multiverse.io\",\n",
      "      \"type\": \"user\"\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "!az login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1634854439863
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ben.dixon/Repos/azure-experiments/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import MLClient, Input\n",
    "from azure.ai.ml.entities import (\n",
    "    BatchEndpoint,\n",
    "    ModelBatchDeployment,\n",
    "    ModelBatchDeploymentSettings,\n",
    "    Model,\n",
    "    Environment,\n",
    "    AmlCompute,\n",
    "    BatchRetrySettings,\n",
    "    CodeConfiguration,\n",
    ")\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml.constants import AssetTypes, BatchDeploymentOutputAction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1634854439994
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: /Users/ben.dixon/Repos/azure-experiments/config.json\n"
     ]
    }
   ],
   "source": [
    "credential = DefaultAzureCredential()\n",
    "ml_client = MLClient.from_config(credential)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create Batch Endpoint\n",
    "Batch endpoints are endpoints that are used batch inferencing on large volumes of data over a period of time. Batch endpoints receive pointers to data and run jobs asynchronously to process the data in parallel on compute clusters. Batch endpoints store outputs to a data store for further analysis.\n",
    "\n",
    "To create an online endpoint we will use `BatchEndpoint`. This class allows user to configure the following key aspects:\n",
    "- `name` - Name of the endpoint. Needs to be unique at the Azure region level\n",
    "- `auth_mode` - The authentication method for the endpoint. Currently only Azure Active Directory (Azure AD) token-based (`aad_token`) authentication is supported. \n",
    "- `description`- Description of the endpoint.\n",
    "\n",
    "## 2.1 Configure the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "name": "name_endpoint"
   },
   "outputs": [],
   "source": [
    "endpoint_name = \"mnist-batch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gather": {
     "logged": 1634854440714
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint name: mnist-batch-vfp7m\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "# Creating a unique endpoint name by including a random suffix\n",
    "allowed_chars = string.ascii_lowercase + string.digits\n",
    "endpoint_suffix = \"\".join(random.choice(allowed_chars) for x in range(5))\n",
    "endpoint_name = f\"{endpoint_name}-{endpoint_suffix}\"\n",
    "\n",
    "print(f\"Endpoint name: {endpoint_name}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's configure the endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "name": "configure_endpoint"
   },
   "outputs": [],
   "source": [
    "endpoint = BatchEndpoint(\n",
    "    name=endpoint_name,\n",
    "    description=\"A batch endpoint for scoring images from the MNIST dataset.\",\n",
    "    tags={\"type\": \"deep-learning\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "name": "create_endpoint"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchEndpoint({'scoring_uri': 'https://mnist-batch-vfp7m.ukwest.inference.ml.azure.com/jobs', 'openapi_uri': None, 'provisioning_state': 'Succeeded', 'name': 'mnist-batch-vfp7m', 'description': 'A batch endpoint for scoring images from the MNIST dataset.', 'tags': {'type': 'deep-learning'}, 'properties': {'BatchEndpointCreationApiVersion': '2023-10-01', 'azureml.onlineendpointid': '/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01/batchEndpoints/mnist-batch-vfp7m'}, 'print_as_yaml': False, 'id': '/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01/batchEndpoints/mnist-batch-vfp7m', 'Resource__source_path': '', 'base_path': '/Users/ben.dixon/Repos/azure-experiments/deploy_batch/mnist-classifier', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x12da0dc10>, 'auth_mode': 'aad_token', 'location': 'ukwest', 'defaults': <azure.ai.ml._restclient.v2023_10_01.models._models_py3.BatchEndpointDefaults object at 0x12da0dfa0>})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Registering the model\n",
    "\n",
    "### 3.1 About the model\n",
    "\n",
    "We are going to deploy a model created using Torch to solve the typical MNIST classification problem."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Registering the model in the workspace\n",
    "\n",
    "We need to register the model in order to use it with Azure Machine Learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "name": "register_model"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading model (0.94 MBs): 100%|██████████| 942407/942407 [00:00<00:00, 2461885.27it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"mnist-classifier-torch\"\n",
    "model_local_path = \"deployment-torch/model/\"\n",
    "\n",
    "model = ml_client.models.create_or_update(\n",
    "    Model(\n",
    "        name=model_name,\n",
    "        path=model_local_path,\n",
    "        type=AssetTypes.CUSTOM_MODEL,\n",
    "        tags={\"task\": \"classification\", \"framework\": \"torch\"},\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a reference to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "name": "get_model"
   },
   "outputs": [],
   "source": [
    "model = ml_client.models.get(name=model_name, label=\"latest\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create a deployment\n",
    "A deployment is a set of resources required for hosting the model that does the actual inferencing."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Creating an scoring script to work with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting deployment-torch/code/batch_driver.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile deployment-torch/code/batch_driver.py\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import glob\n",
    "from os.path import basename\n",
    "from mnist_classifier import MnistClassifier\n",
    "from typing import List\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    global device\n",
    "\n",
    "    # AZUREML_MODEL_DIR is an environment variable created during deployment\n",
    "    # It is the path to the model folder\n",
    "    model_path = os.environ[\"AZUREML_MODEL_DIR\"]\n",
    "    model_file = glob.glob(f\"{model_path}/*/*.pt\")[-1]\n",
    "\n",
    "    model = MnistClassifier()\n",
    "    model.load_state_dict(torch.load(model_file))\n",
    "    model.eval()\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def run(mini_batch: List[str]) -> pd.DataFrame:\n",
    "    print(f\"Executing run method over batch of {len(mini_batch)} files.\")\n",
    "\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for image_path in mini_batch:\n",
    "            image_data = torchvision.io.read_image(image_path).float()\n",
    "            batch_data = image_data.expand(1, -1, -1, -1)\n",
    "            input = batch_data.to(device)\n",
    "\n",
    "            # perform inference\n",
    "            predict_logits = model(input)\n",
    "\n",
    "            # Compute probabilities, classes and labels\n",
    "            predictions = torch.nn.Softmax(dim=-1)(predict_logits)\n",
    "            predicted_prob, predicted_class= torch.max(predictions, axis=-1)\n",
    "            \n",
    "            results.append({ \n",
    "                \"file\": basename(image_path),\n",
    "                \"class\": predicted_class.numpy()[0],\n",
    "                \"probability\": predicted_prob.numpy()[0]\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Creating the compute\n",
    "\n",
    "Batch deployments can run on any Azure ML compute that already exists in the workspace. That means that multiple batch deployments can share the same compute infrastructure. In this example, we are going to work on an AzureML compute cluster called `cpu-cluster`. Let's verify the compute exists on the workspace or create it otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "name": "create_compute"
   },
   "outputs": [],
   "source": [
    "compute_name = \"batch-cluster\"\n",
    "if not any(filter(lambda m: m.name == compute_name, ml_client.compute.list())):\n",
    "    compute_cluster = AmlCompute(\n",
    "        name=compute_name,\n",
    "        description=\"CPU cluster compute\",\n",
    "        min_instances=0,\n",
    "        max_instances=2,\n",
    "    )\n",
    "    ml_client.compute.begin_create_or_update(compute_cluster).result()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute may take time to be created. Let's wait for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for compute batch-cluster [DONE]\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "print(f\"Waiting for compute {compute_name}\", end=\"\")\n",
    "while ml_client.compute.get(name=compute_name).provisioning_state == \"Creating\":\n",
    "    sleep(10)\n",
    "    print(\".\", end=\"\")\n",
    "\n",
    "print(\" [DONE]\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Creating the environment\n",
    "\n",
    "Let's create the environment. In our case, our model runs on `Torch`. Azure Machine Learning already has an environment with the required software installed, so we can reutilize this environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "name": "configure_environment"
   },
   "outputs": [],
   "source": [
    "env = Environment(\n",
    "    name=\"batch-torch-py38\",\n",
    "    conda_file=\"deployment-torch/environment/conda.yaml\",\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Configure the deployment\n",
    "\n",
    "We will create a deployment for our endpoint using the `BatchDeployment` class. This class allows user to configure the following key aspects.\n",
    "\n",
    "Many aspects are similar to online deployment, with these differences: \n",
    "\n",
    "- `scoring_script` - takes in a list and returns a pd.DataFrame\n",
    "- `compute` - Name of the compute target to execute the batch scoring jobs on\n",
    "- `instance_count`- The number of nodes to use for each batch scoring job.\t\t1\n",
    "- `max_concurrency_per_instance`- The maximum number of parallel scoring_script runs per instance.\n",
    "- `mini_batch_size`\t- The number of files the code_configuration.scoring_script can process in one `run()` call.\n",
    "- `retry_settings`- Retry settings for scoring each mini batch.\t\t\n",
    "   - `max_retries`- The maximum number of retries for a failed or timed-out mini batch (default is 3)\n",
    "   - `timeout`- The timeout in seconds for scoring a mini batch (default is 30)\n",
    "- `output_action`- Indicates how the output should be organized in the output file. Allowed values are `append_row` or `summary_only`. Default is `append_row`\n",
    "- `output_file_name`- Name of the batch scoring output file. Default is `predictions.csv`\n",
    "- `environment_variables`- Dictionary of environment variable name-value pairs to set for each batch scoring job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "gather": {
     "logged": 1634854446905
    },
    "name": "configure_deployment"
   },
   "outputs": [],
   "source": [
    "deployment = ModelBatchDeployment(\n",
    "    name=\"mnist-torch-dpl\",\n",
    "    description=\"A deployment using Torch to solve the MNIST classification dataset.\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    model=model,\n",
    "    code_configuration=CodeConfiguration(\n",
    "        code=\"deployment-torch/code/\", scoring_script=\"batch_driver.py\"\n",
    "    ),\n",
    "    environment=env,\n",
    "    compute='ben-small-test',\n",
    "    settings=ModelBatchDeploymentSettings(\n",
    "        max_concurrency_per_instance=1,\n",
    "        mini_batch_size=10,\n",
    "        instance_count=1,\n",
    "        output_action=BatchDeploymentOutputAction.APPEND_ROW,\n",
    "        output_file_name=\"predictions.csv\",\n",
    "        retry_settings=BatchRetrySettings(max_retries=3, timeout=30),\n",
    "        logging_level=\"info\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Create the deployment\n",
    "Using the `MLClient` created earlier, we will now create the deployment in the workspace. This command will start the deployment creation and return a confirmation response while the deployment creation continues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "name": "create_deployment"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchDeployment({'provisioning_state': 'Succeeded', 'endpoint_name': 'mnist-batch-vfp7m', 'type': None, 'name': 'mnist-torch-dpl', 'description': 'A deployment using Torch to solve the MNIST classification dataset.', 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': '/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01/batchEndpoints/mnist-batch-vfp7m/deployments/mnist-torch-dpl', 'Resource__source_path': '', 'base_path': '/Users/ben.dixon/Repos/azure-experiments/deploy_batch/mnist-classifier', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x12de88a90>, 'serialize': <msrest.serialization.Serializer object at 0x12f33e1c0>, 'model': '/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01/models/mnist-classifier-torch/versions/1', 'code_configuration': {'code': '/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01/codes/328559f3-f240-4a8f-a28c-884cd3808b2c/versions/1'}, 'environment': '/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01/environments/batch-torch-py38/versions/1', 'environment_variables': {}, 'compute': '/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01/computes/ben-small-test', 'resources': {'instance_count': 1, 'properties': {}}, 'output_action': 'append_row', 'output_file_name': 'predictions.csv', 'error_threshold': -1, 'retry_settings': <azure.ai.ml.entities._deployment.deployment_settings.BatchRetrySettings object at 0x12de88dc0>, 'logging_level': 'Info', 'mini_batch_size': 10, 'max_concurrency_per_instance': 1})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.begin_create_or_update(deployment).result()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's update the default deployment name in the endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "name": "set_default_deployment"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchEndpoint({'scoring_uri': 'https://mnist-batch-vfp7m.ukwest.inference.ml.azure.com/jobs', 'openapi_uri': None, 'provisioning_state': 'Succeeded', 'name': 'mnist-batch-vfp7m', 'description': 'A batch endpoint for scoring images from the MNIST dataset.', 'tags': {'type': 'deep-learning'}, 'properties': {'BatchEndpointCreationApiVersion': '2023-10-01', 'azureml.onlineendpointid': '/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01/batchEndpoints/mnist-batch-vfp7m'}, 'print_as_yaml': False, 'id': '/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01/batchEndpoints/mnist-batch-vfp7m', 'Resource__source_path': '', 'base_path': '/Users/ben.dixon/Repos/azure-experiments/deploy_batch/mnist-classifier', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x12f33e940>, 'auth_mode': 'aad_token', 'location': 'ukwest', 'defaults': <azure.ai.ml._restclient.v2023_10_01.models._models_py3.BatchEndpointDefaults object at 0x12f328a90>})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint = ml_client.batch_endpoints.get(endpoint_name)\n",
    "endpoint.defaults.deployment_name = deployment.name\n",
    "ml_client.batch_endpoints.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the details of the deployment as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "name": "query_deployment"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchDeployment({'provisioning_state': 'Succeeded', 'endpoint_name': 'mnist-batch-vfp7m', 'type': None, 'name': 'mnist-torch-dpl', 'description': 'A deployment using Torch to solve the MNIST classification dataset.', 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': '/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01/batchEndpoints/mnist-batch-vfp7m/deployments/mnist-torch-dpl', 'Resource__source_path': '', 'base_path': '/Users/ben.dixon/Repos/azure-experiments/deploy_batch/mnist-classifier', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x12e369bb0>, 'serialize': <msrest.serialization.Serializer object at 0x12da0d490>, 'model': '/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01/models/mnist-classifier-torch/versions/1', 'code_configuration': {'code': '/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01/codes/328559f3-f240-4a8f-a28c-884cd3808b2c/versions/1'}, 'environment': '/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01/environments/batch-torch-py38/versions/1', 'environment_variables': {}, 'compute': '/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01/computes/ben-small-test', 'resources': {'instance_count': 1, 'properties': {}}, 'output_action': 'append_row', 'output_file_name': 'predictions.csv', 'error_threshold': -1, 'retry_settings': <azure.ai.ml.entities._deployment.deployment_settings.BatchRetrySettings object at 0x12de88a60>, 'logging_level': 'Info', 'mini_batch_size': 10, 'max_concurrency_per_instance': 1})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.batch_deployments.get(name=deployment.name, endpoint_name=endpoint.name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Test the endpoint with sample data\n",
    "Using the `MLClient` created earlier, we will get a handle to the endpoint. The endpoint can be invoked using the `invoke` command with the following parameters:\n",
    "- `name` - Name of the endpoint\n",
    "- `input_path` - Path where input data is present\n",
    "- `deployment_name` - Name of the specific deployment to test in an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Let's sleep for 2 min to ensure all resources are ready. This is only for automation purposes.\n",
    "time.sleep(120)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.1 Invoke the endpoint\n",
    "\n",
    "Let's now invoke the endpoint for batch scoring job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist-torch-dpl\n",
      "mnist-batch-vfp7m\n"
     ]
    }
   ],
   "source": [
    "print(deployment.name)\n",
    "print(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "name": "start_batch_scoring_job"
   },
   "outputs": [],
   "source": [
    "job = ml_client.batch_endpoints.invoke(\n",
    "    endpoint_name=endpoint_name,\n",
    "    deployment_name=deployment.name,\n",
    "    input=Input(\n",
    "        path=\"https://azuremlexampledata.blob.core.windows.net/data/mnist/sample/\",\n",
    "        type=AssetTypes.URI_FOLDER,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.2 Get the details of the invoked job\n",
    "Let us get details and logs of the invoked job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "name": "get_job"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>mnist-batch-vfp7m</td><td>batchjob-bf7ef713-4b42-430a-a74f-e7b29200cb86</td><td>pipeline</td><td>Running</td><td><a href=\"https://ml.azure.com/runs/batchjob-bf7ef713-4b42-430a-a74f-e7b29200cb86?wsid=/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourcegroups/aiplatform-1/workspaces/ai-mlw-dev-01&amp;tid=7b658efc-8cee-4580-b989-85db158d4e3c\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "PipelineJob({'inputs': {}, 'outputs': {}, 'jobs': {}, 'component': PipelineComponent({'latest_version': None, 'intellectual_property': None, 'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': True, 'auto_delete_setting': None, 'name': 'azureml_anonymous', 'description': \"Attempting to create pipeline submission settings for endpoint: 'mnist-batch-vfp7m', deployment: 'mnist-torch-dpl'.\", 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': None, 'base_path': '/Users/ben.dixon/Repos/azure-experiments/deploy_batch/mnist-classifier', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x12e2a6940>, 'version': '1', 'schema': None, 'type': 'pipeline', 'display_name': 'strong_bread_pz006fl9', 'is_deterministic': None, 'inputs': {}, 'outputs': {}, 'yaml_str': None, 'other_parameter': {}, 'jobs': {}, 'job_types': {}, 'job_sources': {}, 'source_job_id': None}), 'type': 'pipeline', 'status': 'Running', 'log_files': None, 'name': 'batchjob-bf7ef713-4b42-430a-a74f-e7b29200cb86', 'description': \"Attempting to create pipeline submission settings for endpoint: 'mnist-batch-vfp7m', deployment: 'mnist-torch-dpl'.\", 'tags': {'outputType': 'output_data', 'output_data_name': None, 'inputType': 'input_data', 'azureml.batchrun': 'true', 'azureml.deploymentname': 'mnist-torch-dpl', 'azureml.jobtype': 'azureml.batchjob'}, 'properties': {'azureml.deploymentname': 'mnist-torch-dpl', 'azureml.endpointname': 'mnist-batch-vfp7m', 'azureml.pipelineid': '3ac8c399-dd26-4825-818e-afa7d4a2ac62', 'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'Unavailable', 'runType': 'HTTP', 'azureml.parameters': '{\"run_max_try\":\"3\",\"run_invocation_timeout\":\"30\",\"mini_batch_size\":\"10\",\"error_threshold\":\"-1\",\"logging_level\":\"INFO\",\"process_count_per_node\":\"1\",\"NodeCount\":\"1\",\"append_row_file_name\":\"predictions.csv\"}', 'azureml.continue_on_step_failure': 'False', 'azureml.continue_on_failed_optional_input': 'False', 'azureml.pipelineComponent': 'pipelinerun'}, 'print_as_yaml': False, 'id': '/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01/jobs/batchjob-bf7ef713-4b42-430a-a74f-e7b29200cb86', 'Resource__source_path': '', 'base_path': '/Users/ben.dixon/Repos/azure-experiments/deploy_batch/mnist-classifier', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x12e1b4790>, 'serialize': <msrest.serialization.Serializer object at 0x12f33e160>, 'display_name': 'strong_bread_pz006fl9', 'experiment_name': 'mnist-batch-vfp7m', 'compute': None, 'services': {'Tracking': {'endpoint': 'azureml://ukwest.api.azureml.ms/mlflow/v1.0/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/batchjob-bf7ef713-4b42-430a-a74f-e7b29200cb86?wsid=/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourcegroups/aiplatform-1/workspaces/ai-mlw-dev-01&tid=7b658efc-8cee-4580-b989-85db158d4e3c', 'type': 'Studio'}}, 'settings': {}, 'identity': None, 'default_code': None, 'default_environment': None})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.jobs.get(job.name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can wait for the job to finish using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "name": "stream_job_logs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: batchjob-bf7ef713-4b42-430a-a74f-e7b29200cb86\n",
      "Web View: https://ml.azure.com/runs/batchjob-bf7ef713-4b42-430a-a74f-e7b29200cb86?wsid=/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourcegroups/aiplatform-1/workspaces/ai-mlw-dev-01\n",
      "\n",
      "Streaming logs/azureml/executionlogs.txt\n",
      "========================================\n",
      "\n",
      "[2024-05-28 13:17:36Z] Submitting 1 runs, first five are: e7dcd94d:245e2617-e44a-459c-9faa-02e9b0a95c80\n",
      "[2024-05-28 13:22:01Z] Completing processing run id 245e2617-e44a-459c-9faa-02e9b0a95c80.\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: batchjob-bf7ef713-4b42-430a-a74f-e7b29200cb86\n",
      "Web View: https://ml.azure.com/runs/batchjob-bf7ef713-4b42-430a-a74f-e7b29200cb86?wsid=/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourcegroups/aiplatform-1/workspaces/ai-mlw-dev-01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ml_client.jobs.stream(job.name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.3 Download the results\n",
    "\n",
    "The deployment creates a child job that executes the scoring. We can get the details of it using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "scoring_job = list(ml_client.jobs.list(parent_job_name=job.name))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job name: 245e2617-e44a-459c-9faa-02e9b0a95c80\n",
      "Job status: Completed\n",
      "Job duration: 0:00:07.795738\n"
     ]
    }
   ],
   "source": [
    "print(\"Job name:\", scoring_job.name)\n",
    "print(\"Job status:\", scoring_job.status)\n",
    "print(\n",
    "    \"Job duration:\",\n",
    "    scoring_job.creation_context.last_modified_at\n",
    "    - scoring_job.creation_context.created_at,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs generated by the deployment job will be placed in an output named `score`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "name": "download_outputs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifact azureml://datastores/workspaceblobstore/paths/azureml/245e2617-e44a-459c-9faa-02e9b0a95c80/score/ to named-outputs/score\n"
     ]
    }
   ],
   "source": [
    "ml_client.jobs.download(name=scoring_job.name, download_path=\".\", output_name=\"score\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read this data using pandas library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "read_outputs",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7154.png</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7156.png</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7163.png</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7184.png</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7192.png</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971.png</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980.png</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985.png</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991.png</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995.png</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          file  class\n",
       "7154.png     2    1.0\n",
       "7156.png     2    1.0\n",
       "7163.png     2    1.0\n",
       "7184.png     2    1.0\n",
       "7192.png     2    1.0\n",
       "...        ...    ...\n",
       "9971.png     2    1.0\n",
       "9980.png     2    1.0\n",
       "9985.png     2    1.0\n",
       "9991.png     8    1.0\n",
       "9995.png     2    1.0\n",
       "\n",
       "[891 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "score = pd.read_csv(\n",
    "    \"named-outputs/score/predictions.csv\",\n",
    "    header=None,\n",
    "    names=[\"file\", \"class\"],\n",
    "    sep=\" \",\n",
    ")\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file\n",
       "2    262\n",
       "8    256\n",
       "9    118\n",
       "5     90\n",
       "7     89\n",
       "3     57\n",
       "6      7\n",
       "0      6\n",
       "4      5\n",
       "1      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.file.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Override deployment configuration at invocation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.1 Output location\n",
    "\n",
    "You can indicate the output path where you want the job to place the results. To do that, let's first find the ID of a data store registered in AzureML. You can only place outputs in data stores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "name": "get_data_store"
   },
   "outputs": [],
   "source": [
    "batch_ds = ml_client.datastores.get_default()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "name": "start_batch_scoring_job_set_output"
   },
   "outputs": [],
   "source": [
    "filename = f\"predictions-{random.randint(0,99999)}.csv\"\n",
    "\n",
    "job = ml_client.batch_endpoints.invoke(\n",
    "    endpoint_name=endpoint_name,\n",
    "    input=Input(\n",
    "        path=\"https://azuremlexampledata.blob.core.windows.net/data/mnist/sample/\",\n",
    "        type=AssetTypes.URI_FOLDER,\n",
    "    ),\n",
    "    params_override=[\n",
    "        {\"output_dataset.datastore_id\": f\"azureml:{batch_ds.id}\"},\n",
    "        {\"output_dataset.path\": f\"/{endpoint_name}/\"},\n",
    "        {\"output_file_name\": filename},\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find this on the console, go to Data > Datastores > `workspaceblobstore (default)` > `\\{batch_ds.id}\\{endpoint_name}\\{filename}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspaceblobstore/mnist-batch-vfp7m/predictions-54.csv\n"
     ]
    }
   ],
   "source": [
    "print(batch_ds.id.split('/')[-1] + '/' + endpoint_name + '/' + filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.1 Override deployment configuration settings\n",
    "\n",
    "Some other parameters can be override, including `mini_batch_size` and `instance_count`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "start_batch_scoring_job_overwrite"
   },
   "outputs": [],
   "source": [
    "job = ml_client.batch_endpoints.invoke(\n",
    "    endpoint_name=endpoint_name,\n",
    "    input=Input(\n",
    "        path=\"https://azuremlexampledata.blob.core.windows.net/data/mnist/sample/\"\n",
    "    ),\n",
    "    params_override=[{\"mini_batch_size\": \"20\"}, {\"compute.instance_count\": \"5\"}],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Create another deployment\n",
    "\n",
    "Let's now create a second deployment, but this time we will solve the same problem using a model trained with TensorFlow and Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "register_model_non_default"
   },
   "outputs": [],
   "source": [
    "model_name = \"mnist-classifier-keras\"\n",
    "model_local_path = \"deployment-keras/model/\"\n",
    "\n",
    "model = ml_client.models.create_or_update(\n",
    "    Model(\n",
    "        name=model_name,\n",
    "        path=model_local_path,\n",
    "        type=AssetTypes.CUSTOM_MODEL,\n",
    "        tags={\"task\": \"classification\", \"framework\": \"tensorflow\"},\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a reference to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "get_model_non_default"
   },
   "outputs": [],
   "source": [
    "model = ml_client.models.get(name=model_name, label=\"latest\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Creating an scoring script to work with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile deployment-keras/code/batch_driver.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from typing import List\n",
    "from os.path import basename\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "\n",
    "    # AZUREML_MODEL_DIR is an environment variable created during deployment\n",
    "    model_path = os.path.join(os.environ[\"AZUREML_MODEL_DIR\"], \"model\")\n",
    "\n",
    "    # load the model\n",
    "    model = load_model(model_path)\n",
    "\n",
    "def run(mini_batch : List[str]) -> pd.DataFrame:\n",
    "    print(f\"Executing run method over batch of {len(mini_batch)} files.\")\n",
    "\n",
    "    results = []\n",
    "    for image_path in mini_batch:\n",
    "        data = Image.open(image_path)\n",
    "        data = np.array(data)\n",
    "        data_batch = tf.expand_dims(data, axis=0)\n",
    "\n",
    "        # perform inference\n",
    "        pred = model.predict(data_batch)\n",
    "\n",
    "        # Compute probabilities, classes and labels\n",
    "        pred_prob = tf.math.reduce_max(tf.math.softmax(pred, axis=-1)).numpy()\n",
    "        pred_class = tf.math.argmax(pred, axis=-1).numpy()\n",
    "\n",
    "        results.append({\n",
    "            \"file\": basename(image_path), \n",
    "            \"class\": pred_class[0],\n",
    "            \"probability\": pred_prob\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Creating the compute\n",
    "\n",
    "Batch deployments can run on any Azure ML compute that already exists in the workspace. That means that multiple batch deployments can share the same compute infrastructure. In this example, we are going to work on an AzureML compute cluster called `cpu-cluster`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Creating the environment\n",
    "\n",
    "Let's create the environment. In our case, our model runs on `Torch`. Azure Machine Learning already has an environment with the required software installed, so we can reutilize this environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "configure_environment_non_default"
   },
   "outputs": [],
   "source": [
    "env = Environment(\n",
    "    name=\"batch-tensorflow-py38\",\n",
    "    conda_file=\"deployment-keras/environment/conda.yaml\",\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Configure the deployment\n",
    "\n",
    "We will create a deployment for our endpoint using the `BatchDeployment` class. This class allows user to configure the following key aspects.\n",
    "- `name` - Name of the deployment.\n",
    "- `endpoint_name` - Name of the endpoint to create the deployment under.\n",
    "- `model` - The model to use for the deployment. This value can be either a reference to an existing versioned model in the workspace or an inline model specification.\n",
    "- `environment` - The environment to use for the deployment. This value can be either a reference to an existing versioned environment in the workspace or an inline environment specification.\n",
    "- `code_path`- Path to the source code directory for scoring the model\n",
    "- `scoring_script` - Relative path to the scoring file in the source code directory\n",
    "- `compute` - Name of the compute target to execute the batch scoring jobs on\n",
    "- `instance_count`- The number of nodes to use for each batch scoring job.\t\t1\n",
    "- `max_concurrency_per_instance`- The maximum number of parallel scoring_script runs per instance.\n",
    "- `mini_batch_size`\t- The number of files the code_configuration.scoring_script can process in one `run()` call.\n",
    "- `retry_settings`- Retry settings for scoring each mini batch.\t\t\n",
    "   - `max_retries`- The maximum number of retries for a failed or timed-out mini batch (default is 3)\n",
    "   - `timeout`- The timeout in seconds for scoring a mini batch (default is 30)\n",
    "- `output_action`- Indicates how the output should be organized in the output file. Allowed values are `append_row` or `summary_only`. Default is `append_row`\n",
    "- `output_file_name`- Name of the batch scoring output file. Default is `predictions.csv`\n",
    "- `environment_variables`- Dictionary of environment variable name-value pairs to set for each batch scoring job.\n",
    "- `logging_level`- The log verbosity level.\tAllowed values are `warning`, `info`, `debug`. Default is `info`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "configure_deployment_non_default"
   },
   "outputs": [],
   "source": [
    "deployment_keras = ModelBatchDeployment(\n",
    "    name=\"mnist-keras-dpl\",\n",
    "    description=\"A deployment using Keras to solve the MNIST classification dataset.\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    model=model,\n",
    "    code_configuration=CodeConfiguration(\n",
    "        code=\"deployment-keras/code/\", scoring_script=\"batch_driver.py\"\n",
    "    ),\n",
    "    environment=env,\n",
    "    compute=compute_name,\n",
    "    settings=ModelBatchDeploymentSettings(\n",
    "        instance_count=2,\n",
    "        max_concurrency_per_instance=2,\n",
    "        mini_batch_size=10,\n",
    "        output_action=BatchDeploymentOutputAction.APPEND_ROW,\n",
    "        output_file_name=\"predictions.csv\",\n",
    "        retry_settings=BatchRetrySettings(max_retries=3, timeout=30),\n",
    "        logging_level=\"info\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Create the deployment\n",
    "Using the `MLClient` created earlier, we will now create the deployment in the workspace. This command will start the deployment creation and return a confirmation response while the deployment creation continues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "create_deployment_non_default"
   },
   "outputs": [],
   "source": [
    "ml_client.begin_create_or_update(deployment_keras).result()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Test the endpoint with sample data\n",
    "Using the `MLClient` created earlier, we will get a handle to the endpoint. The endpoint can be invoked using the `invoke` command with the following parameters:\n",
    "- `name` - Name of the endpoint\n",
    "- `input_path` - Path where input data is present\n",
    "- `deployment_name` - Name of the specific deployment to test in an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Let's sleep for 2 min to ensure all resources are ready. This is only for automation purposes.\n",
    "time.sleep(120)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6.1 Invoke the endpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now invoke the endpoint for batch scoring job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "test_deployment_non_default"
   },
   "outputs": [],
   "source": [
    "job = ml_client.batch_endpoints.invoke(\n",
    "    endpoint_name=endpoint_name,\n",
    "    deployment_name=deployment_keras.name,\n",
    "    input=Input(\n",
    "        path=\"https://azuremlexampledata.blob.core.windows.net/data/mnist/sample/\",\n",
    "        type=AssetTypes.URI_FOLDER,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6.2 Get the details of the invoked job\n",
    "Let us get details and logs of the invoked job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "get_job_non_default"
   },
   "outputs": [],
   "source": [
    "ml_client.jobs.get(job.name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can wait for the job to finish using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "stream_job_logs_non_default"
   },
   "outputs": [],
   "source": [
    "ml_client.jobs.stream(job.name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6.3 Download the results\n",
    "\n",
    "The deployment creates a child job that executes the scoring. We can get the details of it using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_job = list(ml_client.jobs.list(parent_job_name=job.name))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Job name:\", scoring_job.name)\n",
    "print(\"Job status:\", scoring_job.status)\n",
    "print(\n",
    "    \"Job duration:\",\n",
    "    scoring_job.creation_context.last_modified_at\n",
    "    - scoring_job.creation_context.created_at,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs generated by the deployment job will be placed in an output named `score`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "download_outputs_non_default"
   },
   "outputs": [],
   "source": [
    "ml_client.jobs.download(name=scoring_job.name, download_path=\".\", output_name=\"score\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read this data using pandas library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "read_outputs_non_default"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "score = pd.read_csv(\n",
    "    \"named-outputs/score/predictions.csv\",\n",
    "    header=None,\n",
    "    names=[\"file\", \"class\"],\n",
    "    sep=\" \",\n",
    ")\n",
    "score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Change the default deployment\n",
    "\n",
    "Now that we know the deployment works, we can switch from one deployment to the new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "update_default_deployment"
   },
   "outputs": [],
   "source": [
    "endpoint = ml_client.batch_endpoints.get(endpoint_name)\n",
    "endpoint.defaults.deployment_name = deployment_keras.name\n",
    "ml_client.batch_endpoints.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also delete the old deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "delete_deployment"
   },
   "outputs": [],
   "source": [
    "ml_client.batch_deployments.begin_delete(\n",
    "    endpoint_name=endpoint_name, name=deployment.name\n",
    ").result()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Clean up Resources\n",
    "Delete endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "delete_endpoint"
   },
   "outputs": [],
   "source": [
    "ml_client.batch_endpoints.begin_delete(name=endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "description": {
   "description": "Create and test batch endpoint and deployement"
  },
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
