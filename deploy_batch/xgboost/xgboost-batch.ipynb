{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy locally trained xgboost model to a batch endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mA web browser has been opened at https://login.microsoftonline.com/organizations/oauth2/v2.0/authorize. Please continue the login in the web browser. If no web browser is available or if the web browser fails to open, use device code flow with `az login --use-device-code`.\u001b[0m\n",
      "[\n",
      "  {\n",
      "    \"cloudName\": \"AzureCloud\",\n",
      "    \"homeTenantId\": \"7b658efc-8cee-4580-b989-85db158d4e3c\",\n",
      "    \"id\": \"3979595d-b401-4ff4-b3ef-661b8481c742\",\n",
      "    \"isDefault\": true,\n",
      "    \"managedByTenants\": [\n",
      "      {\n",
      "        \"tenantId\": \"961897a7-5808-4b80-b503-dbb7be13e7a7\"\n",
      "      }\n",
      "    ],\n",
      "    \"name\": \"MV-AZU-001\",\n",
      "    \"state\": \"Enabled\",\n",
      "    \"tenantId\": \"7b658efc-8cee-4580-b989-85db158d4e3c\",\n",
      "    \"user\": {\n",
      "      \"name\": \"ben.dixon@multiverse.io\",\n",
      "      \"type\": \"user\"\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "!az login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gather": {
     "logged": 1634854439863
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient, Input\n",
    "from azure.ai.ml.entities import (\n",
    "    BatchEndpoint,\n",
    "    ModelBatchDeployment,\n",
    "    ModelBatchDeploymentSettings,\n",
    "    Model,\n",
    "    Environment,\n",
    "    AmlCompute,\n",
    "    BatchRetrySettings,\n",
    "    CodeConfiguration,\n",
    ")\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml.constants import AssetTypes, BatchDeploymentOutputAction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gather": {
     "logged": 1634854439994
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: /Users/ben.dixon/Repos/azure-experiments/config.json\n"
     ]
    }
   ],
   "source": [
    "credential = DefaultAzureCredential()\n",
    "ml_client = MLClient.from_config(credential)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create Batch Endpoint\n",
    "Batch endpoints are endpoints that are used batch inferencing on large volumes of data over a period of time. Batch endpoints receive pointers to data and run jobs asynchronously to process the data in parallel on compute clusters. Batch endpoints store outputs to a data store for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "name": "name_endpoint"
   },
   "outputs": [],
   "source": [
    "endpoint_name = \"xgboost-batch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1634854440714
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint name: xgboost-batch-pnp9z\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "# Creating a unique endpoint name by including a random suffix\n",
    "allowed_chars = string.ascii_lowercase + string.digits\n",
    "endpoint_suffix = \"\".join(random.choice(allowed_chars) for x in range(5))\n",
    "endpoint_name = f\"{endpoint_name}-{endpoint_suffix}\"\n",
    "\n",
    "print(f\"Endpoint name: {endpoint_name}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's configure the endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "name": "configure_endpoint"
   },
   "outputs": [],
   "source": [
    "endpoint = BatchEndpoint(\n",
    "    name=endpoint_name,\n",
    "    description=\"A batch endpoint for returning xgboost inferences.\",\n",
    "    tags={\"type\": \"deep-learning\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "name": "create_endpoint"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchEndpoint({'scoring_uri': 'https://xgboost-batch-pnp9z.ukwest.inference.ml.azure.com/jobs', 'openapi_uri': None, 'provisioning_state': 'Succeeded', 'name': 'xgboost-batch-pnp9z', 'description': 'A batch endpoint for returning xgboost inferences.', 'tags': {'type': 'deep-learning'}, 'properties': {'BatchEndpointCreationApiVersion': '2023-10-01', 'azureml.onlineendpointid': '/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01/batchEndpoints/xgboost-batch-pnp9z'}, 'print_as_yaml': False, 'id': '/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01/batchEndpoints/xgboost-batch-pnp9z', 'Resource__source_path': '', 'base_path': '/Users/ben.dixon/Repos/azure-experiments/deploy_batch/xgboost', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x105427f10>, 'auth_mode': 'aad_token', 'location': 'ukwest', 'defaults': <azure.ai.ml._restclient.v2023_10_01.models._models_py3.BatchEndpointDefaults object at 0x10f9a4c10>})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Registering the model\n",
    "\n",
    "Deploy a locally trained model - first we have to register it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model({'job_name': None, 'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'xgboost_model', 'description': 'Model created from local files.', 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': '/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01/models/xgboost_model/versions/22', 'Resource__source_path': '', 'base_path': '/Users/ben.dixon/Repos/azure-experiments/deploy_batch/xgboost', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x10f9d2eb0>, 'serialize': <msrest.serialization.Serializer object at 0x10f9d2e20>, 'version': '22', 'latest_version': None, 'path': 'azureml://subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/workspaces/ai-mlw-dev-01/datastores/workspaceblobstore/paths/LocalUpload/d5fb0d93cd2f9ee52e95cb4874b7a63c/xgboost_model.json', 'datastore': None, 'utc_time_created': None, 'flavors': None, 'arm_type': 'model_version', 'type': 'custom_model', 'stage': 'Development'})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"xgboost_model\"\n",
    "model_local_path = \"assets/xgboost_model.json\"\n",
    "\n",
    "xgboost_model = Model(\n",
    "    path=model_local_path,\n",
    "    type=AssetTypes.CUSTOM_MODEL,\n",
    "    name=model_name,\n",
    "    description=\"Model created from local files.\",\n",
    ")\n",
    "ml_client.models.create_or_update(xgboost_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a reference to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "name": "get_model"
   },
   "outputs": [],
   "source": [
    "model = ml_client.models.get(name=model_name, label=\"latest\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create a deployment\n",
    "A deployment is a set of resources required for hosting the model that does the actual inferencing."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Creating the compute\n",
    "\n",
    "Batch deployments can run on any Azure ML compute that already exists in the workspace. That means that multiple batch deployments can share the same compute infrastructure. In this example, we are going to work on an AzureML compute cluster called `cpu-cluster`. Let's verify the compute exists on the workspace or create it otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "name": "create_compute"
   },
   "outputs": [],
   "source": [
    "compute_name = \"ben-small-test\"\n",
    "# if not any(filter(lambda m: m.name == compute_name, ml_client.compute.list())):\n",
    "#     compute_cluster = AmlCompute(\n",
    "#         name=compute_name,\n",
    "#         description=\"CPU cluster compute\",\n",
    "#         min_instances=0,\n",
    "#         max_instances=2,\n",
    "#     )\n",
    "#     ml_client.compute.begin_create_or_update(compute_cluster).result()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute may take time to be created. Let's wait for it:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Creating the environment\n",
    "\n",
    "Let's create the environment. In our case, our model runs on `Torch`. Azure Machine Learning already has an environment with the required software installed, so we can reutilize this environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "name": "configure_environment"
   },
   "outputs": [],
   "source": [
    "env = Environment(\n",
    "    name=\"xgboost-batch-inference-env\",\n",
    "    conda_file=\"assets/conda.yaml\",\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Configure the deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "gather": {
     "logged": 1634854446905
    },
    "name": "configure_deployment"
   },
   "outputs": [],
   "source": [
    "deployment = ModelBatchDeployment(\n",
    "    name=\"iris-xgboost-depl\",\n",
    "    description=\"A deployment using xgboost to classify Iris data.\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    model=model,\n",
    "    code_configuration=CodeConfiguration(\n",
    "        code=\"assets/\", scoring_script=\"batch_driver.py\"\n",
    "    ),\n",
    "    environment=env,\n",
    "    compute='ben-small-test',\n",
    "    settings=ModelBatchDeploymentSettings(\n",
    "        max_concurrency_per_instance=1,\n",
    "        mini_batch_size=4,\n",
    "        instance_count=1,\n",
    "        output_action=BatchDeploymentOutputAction.APPEND_ROW,\n",
    "        output_file_name=\"predictions.csv\",\n",
    "        retry_settings=BatchRetrySettings(max_retries=3, timeout=30),\n",
    "        logging_level=\"info\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Create the deployment\n",
    "Using the `MLClient` created earlier, we will now create the deployment in the workspace. This command will start the deployment creation and return a confirmation response while the deployment creation continues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "name": "create_deployment"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading assets (0.01 MBs): 100%|██████████| 6588/6588 [00:00<00:00, 19116.93it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BatchDeployment({'provisioning_state': 'Succeeded', 'endpoint_name': 'xgboost-batch-pnp9z', 'type': None, 'name': 'iris-xgboost-depl', 'description': 'A deployment using xgboost to classify Iris data.', 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': '/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01/batchEndpoints/xgboost-batch-pnp9z/deployments/iris-xgboost-depl', 'Resource__source_path': '', 'base_path': '/Users/ben.dixon/Repos/azure-experiments/deploy_batch/xgboost', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x117b4adc0>, 'serialize': <msrest.serialization.Serializer object at 0x117b4aaf0>, 'model': '/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01/models/xgboost_model/versions/22', 'code_configuration': {'code': '/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01/codes/6791da6d-68a6-4511-970b-be5a1cfb9cd8/versions/1'}, 'environment': '/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01/environments/xgboost-batch-inference-env/versions/4', 'environment_variables': {}, 'compute': '/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01/computes/ben-small-test', 'resources': {'instance_count': 1, 'properties': {}}, 'output_action': 'append_row', 'output_file_name': 'predictions.csv', 'error_threshold': -1, 'retry_settings': <azure.ai.ml.entities._deployment.deployment_settings.BatchRetrySettings object at 0x117bc5b80>, 'logging_level': 'Info', 'mini_batch_size': 4, 'max_concurrency_per_instance': 1})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.begin_create_or_update(deployment).result()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's update the default deployment name in the endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "name": "set_default_deployment"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchEndpoint({'scoring_uri': 'https://xgboost-batch-pnp9z.ukwest.inference.ml.azure.com/jobs', 'openapi_uri': None, 'provisioning_state': 'Succeeded', 'name': 'xgboost-batch-pnp9z', 'description': 'A batch endpoint for returning xgboost inferences.', 'tags': {'type': 'deep-learning'}, 'properties': {'BatchEndpointCreationApiVersion': '2023-10-01', 'azureml.onlineendpointid': '/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01/batchEndpoints/xgboost-batch-pnp9z'}, 'print_as_yaml': False, 'id': '/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01/batchEndpoints/xgboost-batch-pnp9z', 'Resource__source_path': '', 'base_path': '/Users/ben.dixon/Repos/azure-experiments/deploy_batch/xgboost', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x117b379d0>, 'auth_mode': 'aad_token', 'location': 'ukwest', 'defaults': <azure.ai.ml._restclient.v2023_10_01.models._models_py3.BatchEndpointDefaults object at 0x117bd2310>})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint = ml_client.batch_endpoints.get(endpoint_name)\n",
    "endpoint.defaults.deployment_name = deployment.name\n",
    "ml_client.batch_endpoints.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the details of the deployment as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "name": "query_deployment"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchDeployment({'provisioning_state': 'Succeeded', 'endpoint_name': 'xgboost-batch-pnp9z', 'type': None, 'name': 'iris-xgboost-depl', 'description': 'A deployment using xgboost to classify Iris data.', 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': '/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01/batchEndpoints/xgboost-batch-pnp9z/deployments/iris-xgboost-depl', 'Resource__source_path': '', 'base_path': '/Users/ben.dixon/Repos/azure-experiments/deploy_batch/xgboost', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x117b37ee0>, 'serialize': <msrest.serialization.Serializer object at 0x117f46640>, 'model': '/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01/models/xgboost_model/versions/22', 'code_configuration': {'code': '/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01/codes/6791da6d-68a6-4511-970b-be5a1cfb9cd8/versions/1'}, 'environment': '/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01/environments/xgboost-batch-inference-env/versions/4', 'environment_variables': {}, 'compute': '/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01/computes/ben-small-test', 'resources': {'instance_count': 1, 'properties': {}}, 'output_action': 'append_row', 'output_file_name': 'predictions.csv', 'error_threshold': -1, 'retry_settings': <azure.ai.ml.entities._deployment.deployment_settings.BatchRetrySettings object at 0x117b4a940>, 'logging_level': 'Info', 'mini_batch_size': 4, 'max_concurrency_per_instance': 1})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.batch_deployments.get(name=deployment.name, endpoint_name=endpoint.name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Test the endpoint with sample data\n",
    "Using the `MLClient` created earlier, we will get a handle to the endpoint. The endpoint can be invoked using the `invoke` command with the following parameters:\n",
    "- `name` - Name of the endpoint\n",
    "- `input_path` - Path where input data is present\n",
    "- `deployment_name` - Name of the specific deployment to test in an endpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.1 Invoke the endpoint\n",
    "\n",
    "Let's now invoke the endpoint for batch scoring job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris-xgboost-depl\n",
      "xgboost-batch-pnp9z\n"
     ]
    }
   ],
   "source": [
    "print(deployment.name)\n",
    "print(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "name": "start_batch_scoring_job"
   },
   "outputs": [],
   "source": [
    "# job = ml_client.batch_endpoints.invoke(\n",
    "#     endpoint_name=endpoint_name,\n",
    "#     deployment_name=deployment.name,\n",
    "#     input=Input(\n",
    "#         path=\"https://azuremlexampledata.blob.core.windows.net/data/mnist/sample/\",\n",
    "#         type=AssetTypes.URI_FOLDER,\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "job = ml_client.batch_endpoints.invoke(\n",
    "    endpoint_name=endpoint_name,\n",
    "    deployment_name=deployment.name,\n",
    "    input=Input(\n",
    "        path=\"assets/batch-requests\",\n",
    "        type=AssetTypes.URI_FOLDER\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.2 Get the details of the invoked job\n",
    "Let us get details and logs of the invoked job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "name": "get_job"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>xgboost-batch-pnp9z</td><td>batchjob-ecf96072-82b5-46d4-ab3f-91ca59027dd2</td><td>pipeline</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/batchjob-ecf96072-82b5-46d4-ab3f-91ca59027dd2?wsid=/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourcegroups/aiplatform-1/workspaces/ai-mlw-dev-01&amp;tid=7b658efc-8cee-4580-b989-85db158d4e3c\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "PipelineJob({'inputs': {}, 'outputs': {}, 'jobs': {}, 'component': PipelineComponent({'latest_version': None, 'intellectual_property': None, 'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': True, 'auto_delete_setting': None, 'name': 'azureml_anonymous', 'description': \"Attempting to create pipeline submission settings for endpoint: 'xgboost-batch-pnp9z', deployment: 'iris-xgboost-depl'.\", 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': None, 'base_path': '/Users/ben.dixon/Repos/azure-experiments/deploy_batch/xgboost', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x117bdd8e0>, 'version': '1', 'schema': None, 'type': 'pipeline', 'display_name': 'funny_orange_z31ty191', 'is_deterministic': None, 'inputs': {}, 'outputs': {}, 'yaml_str': None, 'other_parameter': {}, 'jobs': {}, 'job_types': {}, 'job_sources': {}, 'source_job_id': None}), 'type': 'pipeline', 'status': 'Preparing', 'log_files': None, 'name': 'batchjob-ecf96072-82b5-46d4-ab3f-91ca59027dd2', 'description': \"Attempting to create pipeline submission settings for endpoint: 'xgboost-batch-pnp9z', deployment: 'iris-xgboost-depl'.\", 'tags': {'outputType': 'output_data', 'output_data_name': None, 'inputType': 'input_data', 'azureml.batchrun': 'true', 'azureml.deploymentname': 'iris-xgboost-depl', 'azureml.jobtype': 'azureml.batchjob'}, 'properties': {'azureml.deploymentname': 'iris-xgboost-depl', 'azureml.endpointname': 'xgboost-batch-pnp9z', 'azureml.pipelineid': 'e9cb9913-2e13-4d1d-b6b2-5bf75e6c93d6', 'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'Unavailable', 'runType': 'HTTP', 'azureml.parameters': '{\"run_max_try\":\"3\",\"run_invocation_timeout\":\"30\",\"mini_batch_size\":\"4\",\"error_threshold\":\"-1\",\"logging_level\":\"INFO\",\"process_count_per_node\":\"1\",\"NodeCount\":\"1\",\"append_row_file_name\":\"predictions.csv\"}', 'azureml.continue_on_step_failure': 'False', 'azureml.continue_on_failed_optional_input': 'False', 'azureml.pipelineComponent': 'pipelinerun'}, 'print_as_yaml': False, 'id': '/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01/jobs/batchjob-ecf96072-82b5-46d4-ab3f-91ca59027dd2', 'Resource__source_path': '', 'base_path': '/Users/ben.dixon/Repos/azure-experiments/deploy_batch/xgboost', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x117bdd3a0>, 'serialize': <msrest.serialization.Serializer object at 0x117bd23d0>, 'display_name': 'funny_orange_z31ty191', 'experiment_name': 'xgboost-batch-pnp9z', 'compute': None, 'services': {'Tracking': {'endpoint': 'azureml://ukwest.api.azureml.ms/mlflow/v1.0/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourceGroups/aiplatform-1/providers/Microsoft.MachineLearningServices/workspaces/ai-mlw-dev-01?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/batchjob-ecf96072-82b5-46d4-ab3f-91ca59027dd2?wsid=/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourcegroups/aiplatform-1/workspaces/ai-mlw-dev-01&tid=7b658efc-8cee-4580-b989-85db158d4e3c', 'type': 'Studio'}}, 'settings': {}, 'identity': None, 'default_code': None, 'default_environment': None})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.jobs.get(job.name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can wait for the job to finish using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "name": "stream_job_logs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: batchjob-ecf96072-82b5-46d4-ab3f-91ca59027dd2\n",
      "Web View: https://ml.azure.com/runs/batchjob-ecf96072-82b5-46d4-ab3f-91ca59027dd2?wsid=/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourcegroups/aiplatform-1/workspaces/ai-mlw-dev-01\n",
      "\n",
      "Streaming logs/azureml/executionlogs.txt\n",
      "========================================\n",
      "\n",
      "[2024-05-28 17:04:47Z] Submitting 1 runs, first five are: e8dbd442:6d60f7ab-8c9a-4c11-b682-c84295da2a8a\n",
      "[2024-05-28 17:06:36Z] Execution of experiment failed, update experiment status and cancel running nodes.\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: batchjob-ecf96072-82b5-46d4-ab3f-91ca59027dd2\n",
      "Web View: https://ml.azure.com/runs/batchjob-ecf96072-82b5-46d4-ab3f-91ca59027dd2?wsid=/subscriptions/3979595d-b401-4ff4-b3ef-661b8481c742/resourcegroups/aiplatform-1/workspaces/ai-mlw-dev-01\n"
     ]
    },
    {
     "ename": "JobException",
     "evalue": "Exception : \n {\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Pipeline has failed child jobs. For more details and logs, please go to the job detail page and check the child jobs.\",\n        \"message_format\": \"Pipeline has failed child jobs. {0}\",\n        \"message_parameters\": {},\n        \"reference_code\": \"PipelineHasStepJobFailed\",\n        \"details\": []\n    },\n    \"environment\": \"ukwest\",\n    \"location\": \"ukwest\",\n    \"time\": \"2024-05-28T17:06:36.154881Z\",\n    \"component_name\": \"\"\n} ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJobException\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/azure-experiments/.venv/lib/python3.9/site-packages/azure/core/tracing/decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/Repos/azure-experiments/.venv/lib/python3.9/site-packages/azure/ai/ml/_telemetry/activity.py:289\u001b[0m, in \u001b[0;36mmonitor_with_activity.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tracer\u001b[38;5;241m.\u001b[39mspan():\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m log_activity(\n\u001b[1;32m    287\u001b[0m             logger\u001b[38;5;241m.\u001b[39mpackage_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions\n\u001b[1;32m    288\u001b[0m         ):\n\u001b[0;32m--> 289\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(logger, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpackage_logger\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger\u001b[38;5;241m.\u001b[39mpackage_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions):\n",
      "File \u001b[0;32m~/Repos/azure-experiments/.venv/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:818\u001b[0m, in \u001b[0;36mJobOperations.stream\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_pipeline_child_job(job_object):\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PipelineChildJobError(job_id\u001b[38;5;241m=\u001b[39mjob_object\u001b[38;5;241m.\u001b[39mid)\n\u001b[0;32m--> 818\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream_logs_until_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_runs_operations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datastore_operations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequests_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_requests_pipeline\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/azure-experiments/.venv/lib/python3.9/site-packages/azure/ai/ml/operations/_job_ops_helper.py:334\u001b[0m, in \u001b[0;36mstream_logs_until_completion\u001b[0;34m(run_operations, job_resource, datastore_operations, raise_exception_on_failed_job, requests_pipeline)\u001b[0m\n\u001b[1;32m    332\u001b[0m         file_handle\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m JobException(\n\u001b[1;32m    335\u001b[0m             message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException : \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(json\u001b[38;5;241m.\u001b[39mdumps(error, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)),\n\u001b[1;32m    336\u001b[0m             target\u001b[38;5;241m=\u001b[39mErrorTarget\u001b[38;5;241m.\u001b[39mJOB,\n\u001b[1;32m    337\u001b[0m             no_personal_data_message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException raised on failed job.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    338\u001b[0m             error_category\u001b[38;5;241m=\u001b[39mErrorCategory\u001b[38;5;241m.\u001b[39mSYSTEM_ERROR,\n\u001b[1;32m    339\u001b[0m         )\n\u001b[1;32m    341\u001b[0m file_handle\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    342\u001b[0m file_handle\u001b[38;5;241m.\u001b[39mflush()\n",
      "\u001b[0;31mJobException\u001b[0m: Exception : \n {\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Pipeline has failed child jobs. For more details and logs, please go to the job detail page and check the child jobs.\",\n        \"message_format\": \"Pipeline has failed child jobs. {0}\",\n        \"message_parameters\": {},\n        \"reference_code\": \"PipelineHasStepJobFailed\",\n        \"details\": []\n    },\n    \"environment\": \"ukwest\",\n    \"location\": \"ukwest\",\n    \"time\": \"2024-05-28T17:06:36.154881Z\",\n    \"component_name\": \"\"\n} "
     ]
    }
   ],
   "source": [
    "ml_client.jobs.stream(job.name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.3 Download the results\n",
    "\n",
    "The deployment creates a child job that executes the scoring. We can get the details of it using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "scoring_job = list(ml_client.jobs.list(parent_job_name=job.name))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job name: 00650371-b85f-40c3-a7af-9d4b17dd4645\n",
      "Job status: Failed\n",
      "Job duration: 0:00:07.876290\n"
     ]
    }
   ],
   "source": [
    "print(\"Job name:\", scoring_job.name)\n",
    "print(\"Job status:\", scoring_job.status)\n",
    "print(\n",
    "    \"Job duration:\",\n",
    "    scoring_job.creation_context.last_modified_at\n",
    "    - scoring_job.creation_context.created_at,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs generated by the deployment job will be placed in an output named `score`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "name": "download_outputs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifact azureml://datastores/workspaceblobstore/paths/azureml/00650371-b85f-40c3-a7af-9d4b17dd4645/score/ to named-outputs/score\n"
     ]
    }
   ],
   "source": [
    "ml_client.jobs.download(name=scoring_job.name, download_path=\".\", output_name=\"score\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read this data using pandas library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "read_outputs",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [file, class]\n",
       "Index: []"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "score = pd.read_csv(\n",
    "    \"named-outputs/score/predictions.csv\",\n",
    "    header=None,\n",
    "    names=[\"file\", \"class\"],\n",
    "    sep=\" \",\n",
    ")\n",
    "score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Override deployment configuration at invocation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.1 Output location\n",
    "\n",
    "You can indicate the output path where you want the job to place the results. To do that, let's first find the ID of a data store registered in AzureML. You can only place outputs in data stores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "name": "get_data_store"
   },
   "outputs": [],
   "source": [
    "batch_ds = ml_client.datastores.get_default()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "name": "start_batch_scoring_job_set_output"
   },
   "outputs": [],
   "source": [
    "filename = f\"predictions-{random.randint(0,99999)}.csv\"\n",
    "\n",
    "job = ml_client.batch_endpoints.invoke(\n",
    "    endpoint_name=endpoint_name,\n",
    "    input=Input(\n",
    "        path=\"https://azuremlexampledata.blob.core.windows.net/data/mnist/sample/\",\n",
    "        type=AssetTypes.URI_FOLDER,\n",
    "    ),\n",
    "    params_override=[\n",
    "        {\"output_dataset.datastore_id\": f\"azureml:{batch_ds.id}\"},\n",
    "        {\"output_dataset.path\": f\"/{endpoint_name}/\"},\n",
    "        {\"output_file_name\": filename},\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find this on the console, go to Data > Datastores > `workspaceblobstore (default)` > `\\{batch_ds.id}\\{endpoint_name}\\{filename}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspaceblobstore/mnist-batch-vfp7m/predictions-54.csv\n"
     ]
    }
   ],
   "source": [
    "print(batch_ds.id.split('/')[-1] + '/' + endpoint_name + '/' + filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.1 Override deployment configuration settings\n",
    "\n",
    "Some other parameters can be override, including `mini_batch_size` and `instance_count`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "start_batch_scoring_job_overwrite"
   },
   "outputs": [],
   "source": [
    "job = ml_client.batch_endpoints.invoke(\n",
    "    endpoint_name=endpoint_name,\n",
    "    input=Input(\n",
    "        path=\"https://azuremlexampledata.blob.core.windows.net/data/mnist/sample/\"\n",
    "    ),\n",
    "    params_override=[{\"mini_batch_size\": \"20\"}, {\"compute.instance_count\": \"5\"}],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Clean up Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "delete_endpoint"
   },
   "outputs": [],
   "source": [
    "ml_client.batch_endpoints.begin_delete(name=endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "description": {
   "description": "Create and test batch endpoint and deployement"
  },
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
